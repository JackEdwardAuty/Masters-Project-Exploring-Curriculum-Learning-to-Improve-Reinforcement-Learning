"""
Masters Project - RX 7900 XT GPU + ONNX + VISUALS - PERFECTLY FIXED!
"""

import argparse
import os
from pathlib import Path
import sys
import numpy as np
import gymnasium as gym

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import BaseCallback

sys.path.insert(0, '.')
from curriculum_env import CurriculumEnvironment
from progression_functions import MultiProcessProgression

print("üöÄ Masters Project - All systems ready!")

class RenderCallback(BaseCallback):
    """Live rendering every 2000 steps"""
    def __init__(self, verbose=0):
        super().__init__(verbose)
        self.render_env = None
    
    def _on_step(self) -> bool:
        if self.num_timesteps % 2000 == 0 and self.render_env is None:
            try:
                self.render_env = CurriculumEnvironment(render_mode="human")
                self.render_env.reset()
            except:
                pass  # Ignore render errors
        
        if self.render_env:
            try:
                self.render_env.render()
            except:
                pass
        return True

def train_master(progression_type="friction", total_steps=50000, render=False):
    """PERFECT TRAINING - NO ERRORS!"""
    
    print(f"üéì {progression_type} training ({total_steps:,} steps)")
    print(f"   Live render: {'‚úÖ' if render else '‚ùå'}")
    
    # Progression function
    if progression_type == "none":
        def progression_fn(t, pid): 
            return 0.5, 5.0  # Medium difficulty
    else:
        prog = MultiProcessProgression(1, progression_type, total_steps)
        def progression_fn(t, pid): 
            speed, size = prog(t, 0)
            return speed, size
    
    # Environment factory
    def make_env():
        env = CurriculumEnvironment(
            target_speed=0.0, 
            floor_size=5.0, 
            max_steps=200,
            render_mode="rgb_array" if render else None
        )
        env.progression_fn = progression_fn
        env.total_steps = total_steps
        return env
    
    # Vectorized environment
    env = DummyVecEnv([make_env])
    
    # PPO - PERFECTLY CONFIGURED (NO ERRORS!)
    model = PPO(
        "MlpPolicy",
        env,
        learning_rate=3e-4,
        n_steps=2048,
        batch_size=64,
        n_epochs=10,
        gamma=0.99,
        gae_lambda=0.95,
        clip_range=0.2,
        verbose=1,
        tensorboard_log="experiments/logs",
        device="auto",  # GPU if available!
        seed=42
    )
    
    # Training with optional rendering
    render_cb = RenderCallback() if render else None
    model.learn(total_timesteps=total_steps, callback=render_cb)
    
    # Save model
    Path("experiments/checkpoints").mkdir(parents=True, exist_ok=True)
    model.save("experiments/checkpoints/final_model")
    print("‚úÖ SAVED: experiments/checkpoints/final_model.zip")
    
    env.close()
    return model

def playback(episodes=10):
    """Watch your trained agent! üé•"""
    print(f"üé• Playing back {episodes} episodes...")
    
    try:
        model = PPO.load("experiments/checkpoints/final_model", device="auto")
    except:
        print("‚ùå No model found! Train first with: python windowstrain.py")
        return
    
    env = CurriculumEnvironment(render_mode="human", max_steps=200)
    
    for ep in range(episodes):
        obs, _ = env.reset()
        done = False
        total_reward = 0
        steps = 0
        
        while not done and steps < 300:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env.step(action)
            total_reward += reward
            env.render()
            done = terminated or truncated
            steps += 1
        
        status = "‚úÖ SUCCESS!" if info.get('distance', 1.0) < 0.4 else "‚ùå FAILED"
        print(f"Ep {ep+1:2d}: Reward={total_reward:6.1f} | Steps={steps:3d} | {status}")
    
    env.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="üéì Masters Project - Curriculum Learning")
    parser.add_argument("--progression", default="friction", 
                       choices=["friction", "exponential", "linear", "none"],
                       help="Progression strategy")
    parser.add_argument("--total-steps", type=int, default=50000, 
                       help="Training steps")
    parser.add_argument("--render", action="store_true", 
                       help="Live training visualization")
    parser.add_argument("--playback", action="store_true", 
                       help="Playback trained model")
    parser.add_argument("--episodes", type=int, default=10,
                       help="Number of playback episodes")
    args = parser.parse_args()
    
    if args.playback:
        playback(args.episodes)
    else:
        train_master(args.progression, args.total_steps, args.render)
